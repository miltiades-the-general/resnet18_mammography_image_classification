{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/miltiadesgeneral/resnetmodel?scriptVersionId=117681479\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"!pip install -qU wandb\n!pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu116","metadata":{"execution":{"iopub.status.busy":"2023-01-30T00:44:19.030322Z","iopub.execute_input":"2023-01-30T00:44:19.031255Z","iopub.status.idle":"2023-01-30T00:44:45.652852Z","shell.execute_reply.started":"2023-01-30T00:44:19.031169Z","shell.execute_reply":"2023-01-30T00:44:45.651682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import Libraries\n* Will use pytorch to build and run our model\n* Use pandas to aggregate our data","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch\nfrom torch import Tensor\nimport torchvision\nimport torchvision.transforms as T\nfrom torchvision.utils import make_grid\nfrom torchvision.io import ImageReadMode\nfrom torch.utils.data import DataLoader, Dataset, random_split\n\nimport tensorflow as tf\n\nfrom typing import Type\n# from torchvision.models import resnet18\n\nimport pydicom as dicom\nfrom PIL import Image\nimport imageio\n\nimport numpy as np \nimport pandas as pd\nfrom pathlib import Path\nimport os\nimport math\n\n%matplotlib inline\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nfrom joblib import Parallel, delayed","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-30T00:44:45.655532Z","iopub.execute_input":"2023-01-30T00:44:45.655902Z","iopub.status.idle":"2023-01-30T00:44:53.618739Z","shell.execute_reply.started":"2023-01-30T00:44:45.655863Z","shell.execute_reply":"2023-01-30T00:44:53.617706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nclass CFG:\n    # file paths\n    train_data = \"/kaggle/input/rsna-breast-cancer-detection/train.csv\"\n    test_data = \"/kaggle/input/rsna-breast-cancer-detection/test.csv\"\n    train_images = \"/kaggle/input/rsna-mammography-images-as-pngs/images_as_pngs_512/train_images_processed_512\"\n    test_images = \"/kaggle/input/rsna-breast-cancer-detection/test_images/10008\"\n    \n    # wandb\n    project= user_secrets.get_secret(\"PROJECT\")\n    entity= user_secrets.get_secret(\"ENTITY\")\n    \n    # Device config\n    device = \"GPU\"\n    \n    # image \n    image_size = 256\n    \n    # batching \n    batch_size = 64\n    \n    random_seed = 123\n    num_workers = 2\n    random = True\n    \n    # loss, optimizer, epochs\n    loss_fn = nn.CrossEntropyLoss()\n    epochs = 10\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-01-30T00:44:53.62024Z","iopub.execute_input":"2023-01-30T00:44:53.621138Z","iopub.status.idle":"2023-01-30T00:44:54.000084Z","shell.execute_reply.started":"2023-01-30T00:44:53.621099Z","shell.execute_reply":"2023-01-30T00:44:53.999003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Device Configuration","metadata":{}},{"cell_type":"code","source":"if CFG.device == \"GPU\":\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T00:44:54.002788Z","iopub.execute_input":"2023-01-30T00:44:54.003226Z","iopub.status.idle":"2023-01-30T00:44:54.127348Z","shell.execute_reply.started":"2023-01-30T00:44:54.003187Z","shell.execute_reply":"2023-01-30T00:44:54.126173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Initialize Weights and Biases","metadata":{}},{"cell_type":"code","source":"import wandb\ntry:\n    api_key = user_secrets.get_secret(\"WANDB\")\n\n    wandb.login(key=api_key)\n    anonymous = None\nexcept:\n    anonymous = \"must\"\n    print('To use your W&B account,\\nGo to Add-ons -> Secrets and provide your W&B access token. Use the Label name as WANDB. \\nGet your W&B access token from here: https://wandb.ai/authorize')\nwandb.init(project=CFG.project, entity=CFG.entity)\nwandb.config = {\n  \"learning_rate\": 0.01,\n  \"epochs\": CFG.epochs,\n  \"batch_size\": CFG.batch_size\n}","metadata":{"execution":{"iopub.status.busy":"2023-01-30T00:44:54.128894Z","iopub.execute_input":"2023-01-30T00:44:54.129616Z","iopub.status.idle":"2023-01-30T00:45:28.150276Z","shell.execute_reply.started":"2023-01-30T00:44:54.129574Z","shell.execute_reply":"2023-01-30T00:45:28.149271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import train data","metadata":{}},{"cell_type":"code","source":"TRAIN_DATA_PATH = CFG.train_data\nTRAIN_IMG_PATH = CFG.train_images\nTEST_DATA_PATH = CFG.test_data\nTEST_IMAGE_PATH = CFG.test_images\n\ntrain_df = pd.read_csv(f'{TRAIN_DATA_PATH}')\ntrain_df['image_path'] = f'{TRAIN_IMG_PATH}'\\\n                    + '/' + train_df.patient_id.astype(str)\\\n                    + '/' + train_df.image_id.astype(str)\\\n                    + '.png'\nprint('Train:')\ndisplay(train_df.head(2))","metadata":{"execution":{"iopub.status.busy":"2023-01-30T00:46:08.250577Z","iopub.execute_input":"2023-01-30T00:46:08.250975Z","iopub.status.idle":"2023-01-30T00:46:08.546427Z","shell.execute_reply.started":"2023-01-30T00:46:08.250935Z","shell.execute_reply":"2023-01-30T00:46:08.545072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = train_df[\"cancer\"].value_counts().values\nfig, ax = plt.subplots(figsize=(16, 8), subplot_kw=dict(aspect=\"equal\"))\ndef func(pct, allvals):\n    absolute = int(np.round(pct/100.*np.sum(allvals)))\n    return \"{:.1f}%\\n({:d} g)\".format(pct, absolute)\n\nwedges, texts, autotexts = ax.pie(data, autopct=lambda pct: func(pct, data),\n                                  textprops=dict(color=\"w\"))\nvalues = [\"No Cancer\", \"Cancer\"]\nax.legend(wedges, values,\n          title=\"Diagnosis\",\n          loc=\"center left\",\n          bbox_to_anchor=(1, 0, 0.5, 1))\nplt.setp(autotexts, size=8, weight=\"bold\")\n\nax.set_title(\"Patient Distribution\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-30T00:46:08.552654Z","iopub.execute_input":"2023-01-30T00:46:08.555732Z","iopub.status.idle":"2023-01-30T00:46:08.798485Z","shell.execute_reply.started":"2023-01-30T00:46:08.555675Z","shell.execute_reply":"2023-01-30T00:46:08.7968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data is very asymmetrical with 97.9% of patients presenting negative and 2.1% of patients presenting positive.","metadata":{}},{"cell_type":"code","source":"from sklearn.utils import resample\ncancer_df = train_df[train_df[\"cancer\"] == 1]\nclear_df = train_df[train_df[\"cancer\"] == 0]\n\ncancer_df = resample(cancer_df,\n                    replace=True,\n                    n_samples=len(clear_df),\n                    random_state=123)\ntrain_df = cancer_df.merge(clear_df, how=\"outer\")\n\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2023-01-30T00:46:09.238905Z","iopub.execute_input":"2023-01-30T00:46:09.239607Z","iopub.status.idle":"2023-01-30T00:46:09.695307Z","shell.execute_reply.started":"2023-01-30T00:46:09.23957Z","shell.execute_reply":"2023-01-30T00:46:09.694275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.sample(frac=0.5)\ntrain_df = train_df.reset_index()","metadata":{"execution":{"iopub.status.busy":"2023-01-30T00:46:09.697512Z","iopub.execute_input":"2023-01-30T00:46:09.698183Z","iopub.status.idle":"2023-01-30T00:46:09.753714Z","shell.execute_reply.started":"2023-01-30T00:46:09.698139Z","shell.execute_reply":"2023-01-30T00:46:09.752686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = train_df[\"cancer\"].value_counts().values\nfig, ax = plt.subplots(figsize=(16, 8), subplot_kw=dict(aspect=\"equal\"))\ndef func(pct, allvals):\n    absolute = int(np.round(pct/100.*np.sum(allvals)))\n    return \"{:.1f}%\\n({:d} g)\".format(pct, absolute)\n\nwedges, texts, autotexts = ax.pie(data, autopct=lambda pct: func(pct, data),\n                                  textprops=dict(color=\"w\"))\nvalues = [\"No Cancer\", \"Cancer\"]\nax.legend(wedges, values,\n          title=\"Diagnosis\",\n          loc=\"center left\",\n          bbox_to_anchor=(1, 0, 0.5, 1))\nplt.setp(autotexts, size=8, weight=\"bold\")\n\nax.set_title(\"Patient Distribution\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-30T00:46:09.914402Z","iopub.execute_input":"2023-01-30T00:46:09.914731Z","iopub.status.idle":"2023-01-30T00:46:10.07432Z","shell.execute_reply.started":"2023-01-30T00:46:09.9147Z","shell.execute_reply":"2023-01-30T00:46:10.073346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Pipeline","metadata":{}},{"cell_type":"markdown","source":"Split the train data into a train, val and test dataset\ncomprised of 80% train, 10% val, 10% test","metadata":{}},{"cell_type":"code","source":"# train test split for the train, val\nfrom sklearn.model_selection import train_test_split\ntrain_dataset, val_dataset = train_test_split(train_df, train_size=math.floor(0.80*(len(train_df))), random_state=CFG.random_seed)\nval_dataset, test_dataset = train_test_split(val_dataset, train_size=math.floor(0.50*(len(val_dataset))), random_state=CFG.random_seed)\n\n# reset index\ntrain_dataset.reset_index(inplace=True)\nval_dataset.reset_index(inplace=True)\ntest_dataset.reset_index(inplace=True)\n\n# display the length\ndisplay(len(train_dataset))\ndisplay(len(val_dataset))\ndisplay(len(test_dataset))","metadata":{"execution":{"iopub.status.busy":"2023-01-30T00:46:10.724689Z","iopub.execute_input":"2023-01-30T00:46:10.7251Z","iopub.status.idle":"2023-01-30T00:46:10.840016Z","shell.execute_reply.started":"2023-01-30T00:46:10.725065Z","shell.execute_reply":"2023-01-30T00:46:10.838948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class buildDataset():\n    def __init__(self, X, y, test=False):\n        self.X = X\n        self.y = y\n        self.target_size = [CFG.image_size, CFG.image_size]\n        self.test = test\n        \n    def __getitem__(self, index):\n        \"\"\"generates one sample of the data\"\"\"\n        # Select sample\n        target_size = self.target_size\n        path = self.X[index]\n        y = self.y[index]\n        img = torchvision.io.read_image(path, mode = ImageReadMode.RGB)\n        X = self.transform(img) if not self.test else self.test_transform(img)\n        return X, y\n    \n    transform = T.Compose([\n        T.ToPILImage(),\n        T.Resize(CFG.image_size),\n        T.RandomRotation(45),\n        T.AutoAugment(),\n        T.ToTensor()])\n    \n    test_transform = T.Compose([\n        T.ToPILImage(),\n        T.Resize(CFG.image_size),\n        T.ToTensor()])\n\n    def __len__(self):\n        \"\"\"denotes number of samples\"\"\"\n        return len(self.X)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T00:46:11.053458Z","iopub.execute_input":"2023-01-30T00:46:11.053761Z","iopub.status.idle":"2023-01-30T00:46:11.064484Z","shell.execute_reply.started":"2023-01-30T00:46:11.053733Z","shell.execute_reply":"2023-01-30T00:46:11.063542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the X, y values for the train and val datasets\nX_train = train_dataset[\"image_path\"]\ny_train = train_dataset[\"cancer\"]\n\nX_val = val_dataset[\"image_path\"]\ny_val = val_dataset[\"cancer\"]","metadata":{"execution":{"iopub.status.busy":"2023-01-30T00:46:11.503975Z","iopub.execute_input":"2023-01-30T00:46:11.506337Z","iopub.status.idle":"2023-01-30T00:46:11.516613Z","shell.execute_reply.started":"2023-01-30T00:46:11.506285Z","shell.execute_reply":"2023-01-30T00:46:11.514143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Construct the pytorch datasets for the train and val data\ntrain_dataset = buildDataset(X_train, y_train)\nval_dataset = buildDataset(X_val, y_val)\n\n# Construct the pytorch dataloaders for the train and val data\ntrain_dl = DataLoader(train_dataset, CFG.batch_size, shuffle=CFG.random, num_workers=CFG.num_workers, pin_memory=True)\nval_dl = DataLoader(val_dataset, CFG.batch_size, shuffle=CFG.random, num_workers=CFG.num_workers, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T00:46:11.896333Z","iopub.execute_input":"2023-01-30T00:46:11.896692Z","iopub.status.idle":"2023-01-30T00:46:11.904464Z","shell.execute_reply.started":"2023-01-30T00:46:11.89666Z","shell.execute_reply":"2023-01-30T00:46:11.903188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_images(image, label, nmax=64):\n    fig, ax = plt.subplots(figsize=(8, 8))\n    ax.set_xticks([]); ax.set_yticks([])\n    ax.set_title(label)\n    ax.imshow(make_grid((image.detach()[:nmax]), nrow=8).permute(1, 2, 0))\ndef show_batch(dl, nmax=64):\n    for images, labels in dl:\n        show_images(images, labels, nmax)\n        break","metadata":{"execution":{"iopub.status.busy":"2023-01-30T00:46:12.460875Z","iopub.execute_input":"2023-01-30T00:46:12.461971Z","iopub.status.idle":"2023-01-30T00:46:12.470942Z","shell.execute_reply.started":"2023-01-30T00:46:12.461929Z","shell.execute_reply":"2023-01-30T00:46:12.46974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image, label in train_dl:\n    print(len(label))\n    print(len(image))\n    break","metadata":{"execution":{"iopub.status.busy":"2023-01-30T00:46:12.855635Z","iopub.execute_input":"2023-01-30T00:46:12.856078Z","iopub.status.idle":"2023-01-30T00:46:21.183405Z","shell.execute_reply.started":"2023-01-30T00:46:12.856036Z","shell.execute_reply":"2023-01-30T00:46:21.181749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_batch(train_dl)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T00:46:21.186597Z","iopub.execute_input":"2023-01-30T00:46:21.187506Z","iopub.status.idle":"2023-01-30T00:46:24.89129Z","shell.execute_reply.started":"2023-01-30T00:46:21.187456Z","shell.execute_reply":"2023-01-30T00:46:24.890066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_batch(val_dl)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T00:46:24.8928Z","iopub.execute_input":"2023-01-30T00:46:24.8933Z","iopub.status.idle":"2023-01-30T00:46:28.550863Z","shell.execute_reply.started":"2023-01-30T00:46:24.893237Z","shell.execute_reply":"2023-01-30T00:46:28.549521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pytorch Model","metadata":{}},{"cell_type":"markdown","source":"class ResNet18(nn.Module):\n    def __init__(self, num_classes=2):\n        super(ResNet18, self).__init__()\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True)\n        )\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True)\n        )\n        \n        self.layer3 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True)\n        )\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(256, num_classes)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        \n        \n    def save(self, model_path):\n        torch.save(self.state_dict(), model_path)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-27T21:27:57.502694Z","iopub.execute_input":"2023-01-27T21:27:57.50309Z","iopub.status.idle":"2023-01-27T21:27:57.518506Z","shell.execute_reply.started":"2023-01-27T21:27:57.503054Z","shell.execute_reply":"2023-01-27T21:27:57.517312Z"}}},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-01-30T00:46:28.554163Z","iopub.execute_input":"2023-01-30T00:46:28.558622Z","iopub.status.idle":"2023-01-30T00:46:28.56585Z","shell.execute_reply.started":"2023-01-30T00:46:28.558579Z","shell.execute_reply":"2023-01-30T00:46:28.564705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    # Create a ResNet-18 model\n    model = torchvision.models.resnet18(pretrained=True)\n\n    # Replace the last fully connected layer with a new layer for binary classification\n    model.fc = nn.Linear(512, 2)\n\n    model = model.to(device)\n    return model\n\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-01-30T00:46:28.567252Z","iopub.execute_input":"2023-01-30T00:46:28.568468Z","iopub.status.idle":"2023-01-30T00:46:28.578213Z","shell.execute_reply.started":"2023-01-30T00:46:28.568425Z","shell.execute_reply":"2023-01-30T00:46:28.576971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model()\n#wandb magic\nwandb.watch(model, log_freq=100)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T00:46:28.581776Z","iopub.execute_input":"2023-01-30T00:46:28.587056Z","iopub.status.idle":"2023-01-30T00:46:31.355145Z","shell.execute_reply.started":"2023-01-30T00:46:28.587013Z","shell.execute_reply":"2023-01-30T00:46:31.352317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"class Train:\n    def __init__(self):\n        self = self\n    # Training Function \n    def train(self):\n        num_epochs = CFG.epochs\n        optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n\n        \n        best_accuracy = 0.0 \n\n        print(\"Begin training...\") \n        for epoch in range(1, num_epochs+1): \n            running_train_loss = 0.0 \n            running_accuracy = 0.0 \n            running_vall_loss = 0.0 \n            total = 0 \n\n            # Training Loop \n            for i, data in enumerate(train_dl, 0): \n            #for data in enumerate(train_loader, 0): \n                inputs, outputs = data  # get the input and real species as outputs; data is a list of [inputs, outputs]\n                inputs = torch.as_tensor(inputs, device=\"cuda\")\n                outputs = torch.as_tensor(outputs, device=\"cuda\")\n                optimizer.zero_grad()   # zero the parameter gradients          \n                predicted_outputs = model(inputs)   # predict output from the model \n                train_loss = CFG.loss_fn(predicted_outputs, outputs)   # calculate loss for the predicted output  \n                train_loss.backward()   # backpropagate the loss \n                optimizer.step()        # adjust parameters based on the calculated gradients \n                running_train_loss +=train_loss.item()  # track the loss value \n                wandb.log({\"loss\": running_train_loss})\n                if i % 100 == 99:    # print every 100 mini-batches\n                    print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_train_loss / 2000:.3f}')\n                    running_loss = 0.0\n\n            # Calculate training loss value \n            train_loss_value = running_train_loss/len(train_dl) \n\n\n\n            # Validation Loop \n            with torch.no_grad(): \n                model.eval() \n                for data in val_dl:\n                    inputs, outputs = data\n                    inputs = torch.as_tensor(inputs, device=\"cuda\")\n                    outputs = torch.as_tensor(outputs, device=\"cuda\")\n                    predicted_outputs = model(inputs) \n                    val_loss = CFG.loss_fn(predicted_outputs, outputs) \n\n                    # The label with the highest value will be our prediction \n                    _, predicted = torch.max(predicted_outputs, 1) \n                    running_vall_loss += val_loss.item()  \n                    total += outputs.size(0) \n                    running_accuracy += (predicted == outputs).sum().item() \n\n            # Calculate validation loss value \n            val_loss_value = running_vall_loss/len(val_dl) \n\n            # Calculate accuracy as the number of correct predictions in the validation batch divided by the total number of predictions done.  \n            accuracy = (100 * running_accuracy / total)     \n\n            # Save the model if the accuracy is the best \n            if accuracy > best_accuracy: \n                self.saveModel() \n                best_accuracy = accuracy \n\n            # Print the statistics of the epoch \n            print('Completed training batch', epoch, 'Training Loss is: %.4f' %train_loss_value, 'Validation Loss is: %.4f' %val_loss_value, 'Accuracy is %d %%' % (accuracy))\n    \n    def saveModel(self): \n        path = \"./ResNet18Model2.pth\" \n        torch.save(model.state_dict(), path)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-01-30T01:18:47.580191Z","iopub.execute_input":"2023-01-30T01:18:47.580566Z","iopub.status.idle":"2023-01-30T01:18:47.599321Z","shell.execute_reply.started":"2023-01-30T01:18:47.580534Z","shell.execute_reply":"2023-01-30T01:18:47.598069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Train()\ntrainer.train()\nprint('Finished Training\\n') ","metadata":{"execution":{"iopub.status.busy":"2023-01-30T01:18:52.521928Z","iopub.execute_input":"2023-01-30T01:18:52.522451Z","iopub.status.idle":"2023-01-30T02:31:15.913289Z","shell.execute_reply.started":"2023-01-30T01:18:52.52241Z","shell.execute_reply":"2023-01-30T02:31:15.911957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"checkpoint_path = \"/kaggle/working/ResNet18Model2.pth\"\ncheckpoint  = torch.load(checkpoint_path)\nmodel.load_state_dict(checkpoint, strict=False)\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2023-01-30T02:58:51.395079Z","iopub.execute_input":"2023-01-30T02:58:51.396307Z","iopub.status.idle":"2023-01-30T02:58:51.473856Z","shell.execute_reply.started":"2023-01-30T02:58:51.396265Z","shell.execute_reply":"2023-01-30T02:58:51.472673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test, y_test = test_dataset[\"image_path\"], test_dataset[\"cancer\"]\ntest_dataset = buildDataset(X_test, y_test, test=True)\ntest_dl = DataLoader(test_dataset, CFG.batch_size, shuffle=CFG.random, num_workers=CFG.num_workers, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T02:58:54.694347Z","iopub.execute_input":"2023-01-30T02:58:54.694714Z","iopub.status.idle":"2023-01-30T02:58:54.705414Z","shell.execute_reply.started":"2023-01-30T02:58:54.694683Z","shell.execute_reply":"2023-01-30T02:58:54.703283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Test:\n    def __init__(self, model, test_dl):\n        self.model = model\n        self.test_dl = test_dl\n    def testAccuracy(self):\n        test_dl = self.test_dl\n        accuracy = 0.0\n        total = 0.0\n\n        with torch.no_grad():\n            for data in test_dl:\n                images, labels = data\n                # run the model on the test set to predict labels\n                images = torch.as_tensor(images, device=\"cuda\")\n                labels = torch.as_tensor(labels, device=\"cuda\")\n                outputs = self.model(images)\n                # the label with the highest energy will be our prediction\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                accuracy += (predicted == labels).sum().item()\n\n        # compute the accuracy over all test images\n        accuracy = (100 * accuracy / total)\n        return(accuracy)\n                \n    # Function to show the images\n    def imageshow(self, img):\n        img = img.cpu()\n        img = img / 2 + 0.5     # unnormalize\n        npimg = img.numpy()\n        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n        plt.show()\n\n\n    # Function to test the model with a batch of images and show the labels predictions\n    def testBatch(self):\n        classes = [\"No Cancer\", \"Cancer\"]\n        batch_size = CFG.batch_size\n        test_dl = self.test_dl\n        # get batch of images from the test DataLoader  \n        images, labels = next(iter(test_dl))\n        images = torch.as_tensor(images, device=\"cuda\")\n        labels = torch.as_tensor(labels, device=\"cuda\")\n\n        # show all images as one image grid\n        self.imageshow(torchvision.utils.make_grid(images))\n\n        # Show the real labels on the screen \n        print('Real labels: ', ' '.join('%5s' % classes[labels[j]] \n                                   for j in range(batch_size)))\n\n        # Let's see what if the model identifiers the  labels of those example\n        outputs = model(images)\n\n        # We got the probability for every 10 labels. The highest (max) probability should be correct label\n        _, predicted = torch.max(outputs, 1)\n\n        # Let's show the predicted labels on the screen to compare with the real ones\n        print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] \n                                  for j in range(batch_size)))","metadata":{"execution":{"iopub.status.busy":"2023-01-30T02:58:55.612235Z","iopub.execute_input":"2023-01-30T02:58:55.613291Z","iopub.status.idle":"2023-01-30T02:58:55.63111Z","shell.execute_reply.started":"2023-01-30T02:58:55.613244Z","shell.execute_reply":"2023-01-30T02:58:55.629922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tester = Test(model, test_dl)\ntester.testAccuracy()","metadata":{"execution":{"iopub.status.busy":"2023-01-30T02:58:56.419168Z","iopub.execute_input":"2023-01-30T02:58:56.419525Z","iopub.status.idle":"2023-01-30T02:59:39.433683Z","shell.execute_reply.started":"2023-01-30T02:58:56.419493Z","shell.execute_reply":"2023-01-30T02:59:39.431307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tester = Test(model, test_dl)\ntester.testBatch()","metadata":{"execution":{"iopub.status.busy":"2023-01-30T02:59:39.436308Z","iopub.execute_input":"2023-01-30T02:59:39.43702Z","iopub.status.idle":"2023-01-30T02:59:42.375609Z","shell.execute_reply.started":"2023-01-30T02:59:39.436952Z","shell.execute_reply":"2023-01-30T02:59:42.374271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = torch.tensor([]).to(device=\"cuda\")\ntarget = torch.tensor([]).to(device=\"cuda\")\nfor data in test_dl:\n    images, labels = data\n    # run the model on the test set to predict labels\n    images = torch.as_tensor(images, device=\"cuda\")\n    labels = torch.as_tensor(labels, device=\"cuda\")\n    outputs = model(images)\n    # the label with the highest energy will be our prediction\n    _, predicted = torch.max(outputs.data, 1)\n    preds = torch.cat((preds, predicted), 0)\n    target = torch.cat((target, labels), 0)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T03:54:43.150258Z","iopub.execute_input":"2023-01-30T03:54:43.150631Z","iopub.status.idle":"2023-01-30T03:55:19.899661Z","shell.execute_reply.started":"2023-01-30T03:54:43.1506Z","shell.execute_reply":"2023-01-30T03:55:19.895196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchmetrics.classification import BinaryConfusionMatrix\nmetric = BinaryConfusionMatrix().to(device=\"cuda\")\ncfn_mtrx = metric(preds, target)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T04:07:52.630612Z","iopub.execute_input":"2023-01-30T04:07:52.631021Z","iopub.status.idle":"2023-01-30T04:07:52.642613Z","shell.execute_reply.started":"2023-01-30T04:07:52.63096Z","shell.execute_reply":"2023-01-30T04:07:52.641058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfn_mtrx = pd.DataFrame(cfn_mtrx.cpu().numpy(), columns=[\"Positive\", \"Negative\"])\ncfn_mtrx","metadata":{"execution":{"iopub.status.busy":"2023-01-30T04:08:00.512103Z","iopub.execute_input":"2023-01-30T04:08:00.512489Z","iopub.status.idle":"2023-01-30T04:08:00.529309Z","shell.execute_reply.started":"2023-01-30T04:08:00.512455Z","shell.execute_reply":"2023-01-30T04:08:00.526785Z"},"trusted":true},"execution_count":null,"outputs":[]}]}